{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Sensitivity analysis\n\nBefore run a Data Assimilation it is often necessary to evaluate the sensitivity of the model parameters with respect to a given scenario.\nIn this example, we use the Weil et al dataset and generate 24 possible trajectories varying PERMX and POROS parameters respectively the hydraulic\nconductivity and the porosity of the soil. \n \n*Estimated time to run the notebook = 5min*\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import multiprocessing\nimport os\nimport shutil\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom SALib.analyze import morris as ma\nfrom SALib.plotting import morris as mp\nfrom SALib.sample import morris as ms\n\nfrom pyCATHY import cathy_tools\nfrom pyCATHY.cathy_tools import subprocess_run_multi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "prj_name = \"test0\"\npath2prj = \"weil_exemple_sensitivityAnalysis\"  # add your local path here\nsimu = cathy_tools.CATHY(\n    dirName=path2prj, prj_name=prj_name, clear_src=False, clear_outputs=True\n)\nsimu.run_preprocessor(verbose=False)\nsimu.run_processor(verbose=True)\n\nSPP_map = simu.set_SOIL_defaults(SPP_map_default=True)\ndpsi = simu.read_outputs(\"psi\")\ndsw, _ = simu.read_outputs(\"sw\")\n\nobs_data = np.hstack(dsw)\nlen(obs_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "number of variables, their names, plausible range and if you want to group or not the variable\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "morris_problem = {\n    # There are six variables\n    \"num_vars\": 2,\n    # These are their names\n    \"names\": [\"PERMX\", \"POROS\"],\n    # Plausible ranges over which we'll move the variables\n    \"bounds\": [\n        [1e-5, 1e-3],  # Ks\n        [0.4, 0.6],  # porosity\n    ],\n    # I don't want to group any of these variables together\n    \"groups\": None,\n}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "number_of_trajectories = 2\nsample = ms.sample(morris_problem, number_of_trajectories, num_levels=4)\n# sample = saltelli.sample(morris_problem, number_of_trajectories, num_levels=4)\n# sample = saltelli.sample(problem, 1024)\ndf_sample = pd.DataFrame(sample, columns=morris_problem[\"names\"])\ndf_sample.index.name = \"sample\"\nfor p in morris_problem[\"names\"]:\n    df_sample[\"dev_\" + p] = 1e2 * (df_sample[p] - SPP_map[p]) / SPP_map[p]\nfig, ax = plt.subplots()\nmp.sample_histograms(fig, sample, morris_problem)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pathexe_list = []\nsimu_ensemble = np.zeros((len(obs_data), len(sample)))\nfor ii in range(0, len(sample)):\n    path_exe = os.path.join(\n        simu.workdir, prj_name + \"_sensitivity\", \"sample\" + str(ii + 1)\n    )\n    pathexe_list.append(path_exe)\n    if os.path.exists(\n        os.path.join(simu.workdir, prj_name + \"_sensitivity\", \"sample\" + str(ii + 1))\n    ):\n        continue\n    else:\n        shutil.copytree(\n            prj_name,\n            os.path.join(\n                simu.workdir, prj_name + \"_sensitivity\", \"sample\" + str(ii + 1)\n            ),\n        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "for ii in range(0, len(sample)):\n    PERMX = PERMY = PERMZ = sample[ii, 0]\n    POROS = sample[ii, 1]\n    SoilPhysProp = {\n        \"PERMX\": PERMX,\n        \"PERMY\": PERMY,\n        \"PERMZ\": PERMZ,\n        \"ELSTOR\": SPP_map[\"ELSTOR\"],\n        \"POROS\": POROS,\n        \"VGNCELL\": SPP_map[\"VGNCELL\"],\n        \"VGRMCCELL\": SPP_map[\"VGRMCCELL\"],\n        \"VGPSATCELL\": SPP_map[\"VGPSATCELL\"],\n    }\n\n    simu.update_soil(SPP_map=SoilPhysProp, path=pathexe_list[ii] + \"/input/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "with multiprocessing.Pool(processes=multiprocessing.cpu_count()) as pool:\n    result = pool.map(subprocess_run_multi, pathexe_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "simu_ensemble = np.zeros((len(obs_data), len(sample)))\nfor ii in range(0, len(sample)):\n    dpsi = simu.read_outputs(\"psi\", path=pathexe_list[ii] + \"/output/\")\n    dsw, _ = simu.read_outputs(\"sw\", path=pathexe_list[ii] + \"/output/\")\n    simu_ensemble[:, ii] = np.hstack(dsw)\n\n# Perform the sensitivity analysis using the model output\n# Specify which column of the output file to analyze (zero-indexed)\n# Si = ma.analyze(\n#     morris_problem,\n#     sample,\n#     rmse,\n#     conf_level=0.95,\n#     print_to_console=True,\n# )\n# Returns a dictionary with keys 'mu', 'mu_star', 'sigma', and 'mu_star_conf'\n# e.g. Si['mu_star'] contains the mu* value for each parameter, in the\n# same order as the parameter file\n\nfrom SALib.plotting.morris import (\n    covariance_plot,\n    horizontal_bar_plot,\n    sample_histograms,\n)\n\n# fig, (ax1, ax2) = plt.subplots(1, 2)\n# horizontal_bar_plot(ax1, Si, {}, sortby=\"mu_star\", unit=r\"tCO$_2$/year\")\n# covariance_plot(ax2, Si, {}, unit=r\"tCO$_2$/year\")\n\n# fig2 = plt.figure()\n# sample_histograms(fig2, sample, morris_problem, {\"color\": \"y\"})\n# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def err_weighted_rmse(sim, obs, noise):\n    y = np.divide(sim - obs, noise)  # weighted data misfit\n    y = np.sqrt(np.inner(y, y))\n    return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "rmse = np.zeros((1, len(sample)))\nfor ii in range(0, len(sample)):\n    rmse[0, ii] = err_weighted_rmse(\n        simu_ensemble[:, ii], obs_data, 0.025 * obs_data\n    )  # assume 2.5% noise in the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "Si = ma.analyze(morris_problem, sample, rmse, print_to_console=True)\n\nprint(\"{:20s} {:>7s} {:>7s} {:>7s}\".format(\"Name\", \"mean(EE)\", \"mean(|EE|)\", \"std(EE)\"))\nfor name, s1, st, mean in zip(\n    morris_problem[\"names\"], Si[\"mu\"], Si[\"mu_star\"], Si[\"sigma\"]\n):\n    print(\"{:20s} {:=7.3f} {:=7.3f} {:=7.3f}\".format(name, s1, st, mean))\n\n# total_Si, first_Si, second_Si = Si.to_df()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots()\nmp.covariance_plot(ax, Si)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The higher mean |EE|, the more important factor\nline within the dashed envelope means nonlinear or interaction effects dominant\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots()\nax.scatter(Si[\"mu_star\"], Si[\"sigma\"])\n# ax.plot(Si['mu_star'],2*Si['sigma']/np.sqrt(number_of_trajectories),'--',alpha=0.5)\n# ax.plot(np.array([0,Si['mu_star'][0]]),2*np.array([0,Si['sigma'][0]/np.sqrt(number_of_trajectories)]),'--',alpha=0.5)\n\nplt.title(\"Distribution of Elementary effects\")\nplt.xlabel(\"mean(|EE|)\")\nplt.ylabel(\"std($EE$)\")\nfor i, txt in enumerate(Si[\"names\"]):\n    ax.annotate(txt, (Si[\"mu_star\"][i], Si[\"sigma\"][i]))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}